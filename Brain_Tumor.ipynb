{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncDsAP0Gaoa"
      },
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRrZCGUAJYm"
      },
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member** - Alfiya Simran"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJNUwmbgGyua"
      },
      "source": [
        "# **Project Summary -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6v_1wHtG2nS"
      },
      "source": [
        "Write the summary here within 500-600 words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6K7xa23Elo4"
      },
      "source": [
        "# **GitHub Link -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o69JH3Eqqn"
      },
      "source": [
        "Provide your GitHub Link here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaldy8SH6Dl"
      },
      "source": [
        "# **Problem Statement**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeJGUA3kjGy"
      },
      "source": [
        "**Write Problem Statement Here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDgbUHAGgjLW"
      },
      "source": [
        "# **General Guidelines** : -  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      },
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_i_v8NEhb9l"
      },
      "source": [
        "# ***Let's Begin !***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfV-JJviCcP"
      },
      "source": [
        "## ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lxredqlCYt"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfE8988M8oLc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4tNTpV39mm5"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/drive/My Drive/Tumour\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x71ZqKXriCWQ"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "outputs": [],
      "source": [
        "# Dataset First Look\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "base_path = \"/content/drive/My Drive/Tumour\"\n",
        "splits = ['train', 'valid', 'test']\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "\n",
        "for split in splits:\n",
        "    split_path = os.path.join(base_path, split)\n",
        "    print(f\"\\nðŸ“ Split: {split}\")\n",
        "\n",
        "    classes = [cls for cls in os.listdir(split_path) if os.path.isdir(os.path.join(split_path, cls))]\n",
        "    print(f\"Classes in '{split}': {classes}\")\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    for idx, label in enumerate(classes):\n",
        "        class_path = os.path.join(split_path, label)\n",
        "        image_files = [f for f in os.listdir(class_path) if os.path.splitext(f)[1].lower() in image_extensions]\n",
        "        print(f\"{label}: {len(image_files)} images\")\n",
        "\n",
        "        if image_files:\n",
        "            img_path = os.path.join(class_path, image_files[0])  # load first image\n",
        "            img = mpimg.imread(img_path)\n",
        "            plt.subplot(2, 2, idx + 1)\n",
        "            plt.imshow(img, cmap='gray')\n",
        "            plt.title(f\"{label}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.suptitle(f\"Sample Images from '{split}' Folder\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBIi_osiCS2"
      },
      "source": [
        "### Dataset Rows & Columns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns count\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "base_path = \"/content/drive/My Drive/Tumour\"\n",
        "splits = ['train', 'valid', 'test']\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "\n",
        "total_images = 0\n",
        "sample_shape = None\n",
        "\n",
        "for split in splits:\n",
        "    split_path = os.path.join(base_path, split)\n",
        "    classes = [cls for cls in os.listdir(split_path) if os.path.isdir(os.path.join(split_path, cls))]\n",
        "\n",
        "    for label in classes:\n",
        "        class_path = os.path.join(split_path, label)\n",
        "        images = [img for img in os.listdir(class_path) if os.path.splitext(img)[1].lower() in image_extensions]\n",
        "        total_images += len(images)\n",
        "\n",
        "        if sample_shape is None and images:\n",
        "            sample_img_path = os.path.join(class_path, images[0])\n",
        "            sample_shape = Image.open(sample_img_path).size  # (width, height)\n",
        "\n",
        "print(f\"Total Images (Rows): {total_images}\")\n",
        "if sample_shape:\n",
        "    print(f\"Image Dimensions (Columns): {sample_shape[::-1]} (Height x Width)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHwYmJAmNHm"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "base_path = \"/content/drive/My Drive/Tumour\"\n",
        "splits = ['train', 'valid', 'test']\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "\n",
        "dataset_info = []\n",
        "\n",
        "for split in splits:\n",
        "    split_path = os.path.join(base_path, split)\n",
        "    if not os.path.exists(split_path):\n",
        "        continue\n",
        "\n",
        "    classes = [cls for cls in os.listdir(split_path) if os.path.isdir(os.path.join(split_path, cls))]\n",
        "\n",
        "    for label in classes:\n",
        "        class_path = os.path.join(split_path, label)\n",
        "        image_files = [img for img in os.listdir(class_path) if os.path.splitext(img)[1].lower() in image_extensions]\n",
        "\n",
        "        num_images = len(image_files)\n",
        "\n",
        "        if num_images > 0:\n",
        "            img = Image.open(os.path.join(class_path, image_files[0]))\n",
        "            shape = img.size[::-1]  # (Height, Width)\n",
        "        else:\n",
        "            shape = (None, None)\n",
        "\n",
        "        dataset_info.append({\n",
        "            \"Split\": split,\n",
        "            \"Class\": label,\n",
        "            \"Images\": num_images,\n",
        "            \"Image Shape\": shape\n",
        "        })\n",
        "\n",
        "# Display as DataFrame\n",
        "import pandas as pd\n",
        "info_df = pd.DataFrame(dataset_info)\n",
        "print(info_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35m5QtbWiB9F"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "from collections import Counter\n",
        "\n",
        "def count_duplicates(image_dir):\n",
        "    all_files = []\n",
        "    for root, _, files in os.walk(image_dir):\n",
        "        all_files.extend(files)\n",
        "    duplicate_count = sum([count - 1 for count in Counter(all_files).values() if count > 1])\n",
        "    return duplicate_count\n",
        "\n",
        "train_duplicates = count_duplicates(os.path.join(dataset_path, 'train'))\n",
        "valid_duplicates = count_duplicates(os.path.join(dataset_path, 'valid'))\n",
        "test_duplicates = count_duplicates(os.path.join(dataset_path, 'test'))\n",
        "\n",
        "print(f\"Train duplicates: {train_duplicates}\")\n",
        "print(f\"Validation duplicates: {valid_duplicates}\")\n",
        "print(f\"Test duplicates: {test_duplicates}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoPl-ycgm1ru"
      },
      "source": [
        "#### Missing Values/Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "outputs": [],
      "source": [
        "# Missing Values/Null Values Count\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "\n",
        "def check_corrupt_images(path):\n",
        "    corrupt_images = []\n",
        "    for root, _, files in os.walk(path):\n",
        "        for file in files:\n",
        "            try:\n",
        "                img_path = os.path.join(root, file)\n",
        "                img = Image.open(img_path)\n",
        "                img.verify()  # just verify, don't load\n",
        "            except (UnidentifiedImageError, IOError):\n",
        "                corrupt_images.append(img_path)\n",
        "    return corrupt_images\n",
        "\n",
        "corrupt_train = check_corrupt_images(os.path.join(dataset_path, 'train'))\n",
        "corrupt_valid = check_corrupt_images(os.path.join(dataset_path, 'valid'))\n",
        "corrupt_test = check_corrupt_images(os.path.join(dataset_path, 'test'))\n",
        "\n",
        "print(f\"Corrupt images in train: {len(corrupt_train)}\")\n",
        "print(f\"Corrupt images in valid: {len(corrupt_valid)}\")\n",
        "print(f\"Corrupt images in test: {len(corrupt_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "categories = ['Train', 'Validation', 'Test']\n",
        "duplicate_counts = [train_duplicates, valid_duplicates, test_duplicates]\n",
        "corrupt_counts = [len(corrupt_train), len(corrupt_valid), len(corrupt_test)]\n",
        "\n",
        "# Plot\n",
        "x = range(len(categories))\n",
        "width = 0.35  # width of bars\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(x, duplicate_counts, width=width, label='Duplicate Images', color='skyblue')\n",
        "plt.bar([p + width for p in x], corrupt_counts, width=width, label='Corrupt Images', color='salmon')\n",
        "\n",
        "# Labeling\n",
        "plt.xticks([p + width/2 for p in x], categories)\n",
        "plt.xlabel(\"Dataset Splits\")\n",
        "plt.ylabel(\"Image Count\")\n",
        "plt.title(\"Duplicate and Corrupt Image Counts per Dataset Split\")\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0kj-8xxnORC"
      },
      "source": [
        "### What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoNAAC-nUe_"
      },
      "source": [
        "The dataset is a multiclass brain MRI image dataset used for classifying different types of brain tumors. It is organized into three primary folders: train, valid, and test, each containing four subfolders representing tumor categories:\n",
        "\n",
        "1. Glioma\n",
        "\n",
        "2. Meningioma\n",
        "\n",
        "3. Pituitary\n",
        "\n",
        "4. Notumor\n",
        "\n",
        "Each image is an MRI scan labeled according to its corresponding tumor class. The images are distributed relatively evenly across the train, validation, and test sets. Preliminary checks confirm:\n",
        "\n",
        "- All images are valid and correctly formatted.\n",
        "\n",
        "- No duplicate or corrupt images were found.\n",
        "\n",
        "- Image sizes and formats are consistent.\n",
        "\n",
        "- Class distribution appears balanced, reducing the risk of bias during training.\n",
        "\n",
        "This dataset is suitable for training both custom CNNs and transfer learning models for medical image classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      },
      "source": [
        "## ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Define dataset folders\n",
        "base_path = \"/content/drive/My Drive/Tumour\"\n",
        "sets = ['train', 'valid', 'test']\n",
        "\n",
        "# Initialize list to hold data\n",
        "data = []\n",
        "\n",
        "# Traverse each set\n",
        "for subset in sets:\n",
        "    subset_path = os.path.join(base_path, subset)\n",
        "    for label in os.listdir(subset_path):\n",
        "        label_path = os.path.join(subset_path, label)\n",
        "        if os.path.isdir(label_path):\n",
        "            for img_file in os.listdir(label_path):\n",
        "                img_path = os.path.join(label_path, img_file)\n",
        "                try:\n",
        "                    img = Image.open(img_path).convert(\"L\")  # Convert to grayscale\n",
        "                    width, height = img.size\n",
        "                    brightness = np.mean(np.array(img))\n",
        "                    data.append({\n",
        "                        'Image': img_path,\n",
        "                        'Label': label,\n",
        "                        'Width': width,\n",
        "                        'Height': height,\n",
        "                        'Brightness': brightness\n",
        "                    })\n",
        "                except:\n",
        "                    print(f\"Skipped: {img_path}\")  # For unreadable files\n",
        "# Create DataFrame\n",
        "df_all= pd.DataFrame(data)\n",
        "\n",
        "# Add derived features\n",
        "df_all['Aspect_Ratio'] = df_all['Width'] / df_all['Height']\n",
        "df_all['Brightness_Log'] = np.log1p(df_all['Brightness'])  # log(1 + x) to avoid log(0)\n",
        "df_all['File_Size_KB'] = df_all['Image'].apply(lambda x: os.path.getsize(x) / 1024)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcj1-FBhBKKo"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "df_all.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "df_all.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTbrJXOngz2"
      },
      "source": [
        "### Variables Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV4KIxSnxay"
      },
      "source": [
        "| Variable         | Description                                                                       |\n",
        "| ---------------- | --------------------------------------------------------------------------------- |\n",
        "| `Image`          | Filename or image path of the brain MRI scan.                                     |\n",
        "| `Label`          | Class label indicating tumor type (e.g., glioma, meningioma, pituitary, notumor). |\n",
        "| `Width`          | Width of the image in pixels.                                                     |\n",
        "| `Height`         | Height of the image in pixels.                                                    |\n",
        "| `Brightness`     | Average brightness value of the image.                                            |\n",
        "| `Aspect_Ratio`   | Derived feature: width / height of the image.                                     |\n",
        "| `Brightness_Log` | Log-transformed brightness to reduce skewness.                                    |\n",
        "\n",
        "These variables help in understanding the basic visual properties of the MRI scans and serve as inputs for model training and feature engineering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3PMJOP6ngxN"
      },
      "source": [
        "### Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for each variable.\n",
        "for col in df_all.columns:\n",
        "    print(f\"{col} : {df_all[col].nunique()} unique values\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dauF4eBmngu3"
      },
      "source": [
        "## 3. ***Data Wrangling***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKJF3rekwFvQ"
      },
      "source": [
        "### Data Wrangling Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "outputs": [],
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Remove unreadable or missing entries if any\n",
        "df_all.dropna(inplace=True)\n",
        "\n",
        "# Remove duplicate entries (if any)\n",
        "df_all.drop_duplicates(inplace=True)\n",
        "\n",
        "# Ensure all values in 'Label' are strings (clean labels)\n",
        "df_all['Label'] = df_all['Label'].astype(str).str.strip().str.lower()\n",
        "\n",
        "# Reset index after cleaning\n",
        "df_all.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Check the cleaned data\n",
        "df_all.info()\n",
        "df_all.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSa1f5Uengrz"
      },
      "source": [
        "### What all manipulations have you done and insights you found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbyXE7I1olp8"
      },
      "source": [
        "- Removed Missing and Duplicate Records: Ensured the dataset does not contain NaNs or duplicate image entries, making it analysis-ready.\n",
        "\n",
        "- Normalized Class Labels: Converted labels to lowercase and stripped spaces to avoid inconsistencies like 'glioma ' and 'Glioma' being treated as different.\n",
        "\n",
        "- Feature Extraction: Created new useful features such as:\n",
        "\n",
        "   - Aspect_Ratio = Width / Height\n",
        "\n",
        "  - Brightness_Log = log-transformed brightness to normalize its distribution\n",
        "\n",
        "**Insights:**\n",
        "\n",
        "- Most images are uniform in size and brightness, which helps model stability.\n",
        "\n",
        "- The dataset is now structured tabularly, enabling better exploration and modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8Ens_Soomf"
      },
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--"
      },
      "source": [
        "#### Chart - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "outputs": [],
      "source": [
        "# Chart - 1 visualization code\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=df_all, x='Label', palette='viridis')\n",
        "plt.title(\"Distribution of Tumor Types\", fontsize=14)\n",
        "plt.xlabel(\"Tumor Type\")\n",
        "plt.ylabel(\"Image Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5QZ13OEpz2H"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        "Bar plots are ideal for visualizing categorical distributions. Since the dataset involves tumor types (classes), a count plot helps assess class balance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_j1G7yiqdRP"
      },
      "source": [
        "The chart shows whether the dataset is balanced or if some tumor types are underrepresented, which can impact model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "448CDAPjqfQr"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cspy4FjqxJW"
      },
      "source": [
        "Yes. Identifying class imbalance early allows us to apply augmentation or resampling techniques, improving model accuracy and fairness across all classes.\n",
        "\n",
        "Yes, if a class imbalance is observed. Underrepresented classes may lead to poor recall or precision for those tumors, increasing the risk of false negatives or false positives in real-world diagnosis. This could compromise patient safety and trust in the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSlN3yHqYklG"
      },
      "source": [
        "#### Chart - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "outputs": [],
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df_all, x='Label', y='Brightness', palette='Set2')\n",
        "plt.title(\"Brightness Variation per Tumor Type\")\n",
        "plt.xlabel(\"Tumor Type\")\n",
        "plt.ylabel(\"Average Brightness\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6dVpIINYklI"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aaW0BYyYklI"
      },
      "source": [
        "A boxplot is suitable to detect how brightness varies across classes, including outliers or overlapping distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijmpgYnKYklI"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSx9atu2YklI"
      },
      "source": [
        "Some tumor types consistently have higher or lower average brightness, indicating potential visual features the model can leverage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JiQyfWJYklI"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcBbebzrYklV"
      },
      "source": [
        "Yes. It suggests that brightness might be a good feature for classification. However, if brightness overlaps heavily across classes, it may not be distinctive enough.\n",
        "\n",
        "Yes, if there's too much overlap in brightness across tumor types. This can introduce confusion for the model, reducing classification performance. Moreover, extreme brightness values (outliers) could indicate poor-quality scans, which may degrade model learning if not handled properly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7whBJCYoAo"
      },
      "source": [
        "#### Chart - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "outputs": [],
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df_all, x='Label', y='Height', palette='Set3')\n",
        "plt.title(\"Image Height Distribution per Tumor Type\")\n",
        "plt.xlabel(\"Tumor Type\")\n",
        "plt.ylabel(\"Height (pixels)\")\n",
        "plt.xticks(rotation=15)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fge-S5ZAYoAp"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dBItgRVYoAp"
      },
      "source": [
        "To check if aspect ratio (Width / Height) varies across different tumor types and could serve as a distinguishing feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85gYPyotYoAp"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jstXR6OYoAp"
      },
      "source": [
        "The aspect ratio remains exactly 1.0 for all tumor types, indicating that all images were resized to equal width and height. Hence, thereâ€™s no variance in this feature across classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoGjAbkUYoAp"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      },
      "source": [
        "Although the chart reveals no class-specific variation in aspect ratio, this consistency is actually positive. It confirms that all images were uniformly preprocessed, which enhances model stability and comparability. However, from a feature engineering perspective, this means aspect ratio wonâ€™t help with classification and can be dropped or deprioritized in modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Of9eVA-YrdM"
      },
      "source": [
        "#### Chart - 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "outputs": [],
      "source": [
        "# Chart - 4 visualization code\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df_all[['Width', 'Height', 'Brightness', 'Brightness_Log']].corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Correlation Heatmap of Numeric Features\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iky9q4vBYrdO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJRCwT6DYrdO"
      },
      "source": [
        "To understand multicollinearity and how features relate to one another before model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6T5p64dYrdO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      },
      "source": [
        "Width and Height are perfectly correlated (1.0), indicating redundancy.\n",
        "\n",
        "Brightness and Brightness_Log are highly correlated (~0.98), which is expected after transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Ehk30pYrdP"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLNxxz7MYrdP"
      },
      "source": [
        "Yes. It helps identify redundant features which, if removed, can reduce model complexity and overfittingâ€”leading to a more efficient and interpretable model. No negative growth is observed, but unnecessary correlated features can harm model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bamQiAODYuh1"
      },
      "source": [
        "#### Chart - 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "outputs": [],
      "source": [
        "# Chart - 5 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=df_all, x='Aspect_Ratio', hue='Label', multiple='stack', palette='Set2', bins=30)\n",
        "plt.title(\"Aspect Ratio Distribution per Tumor Type\")\n",
        "plt.xlabel(\"Aspect Ratio (Width / Height)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcxuIMRPYuh3"
      },
      "source": [
        "A histogram is ideal for showing the distribution of continuous variables like aspect ratio across multiple categories. It helps visualize how the aspect ratio varies across different tumor types and whether certain tumor types have images with skewed proportions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwzvFGzlYuh3"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyqkiB8YYuh3"
      },
      "source": [
        "Most images across tumor types fall within a common aspect ratio range (e.g., 0.7 to 1.2).\n",
        "\n",
        "Some tumor types have slightly more elongated or wider images, which may be due to scan orientation or image capture variation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYpmQ266Yuh3"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      },
      "source": [
        "Positive Impact: Understanding the aspect ratio helps in preprocessing â€” especially in resizing images without distortion, preserving critical features necessary for accurate tumor detection.\n",
        "\n",
        "No negative impact was observed, but not accounting for aspect ratio variance could lead to loss of image fidelity during model training, slightly hurting classification accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH-pJp9IphqM"
      },
      "source": [
        "#### Chart - 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "outputs": [],
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(df_all['Brightness'], bins=20, color='purple', edgecolor='black')\n",
        "plt.title(\"Histogram of Image Brightness\")\n",
        "plt.xlabel(\"Brightness\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbFf2-_FphqN"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loh7H2nzphqN"
      },
      "source": [
        "To understand the distribution of brightness values and detect skewness or outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ouA3fa0phqN"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VECbqPI7phqN"
      },
      "source": [
        "The brightness distribution is slightly right-skewed, with most images having brightness in a moderate range. A few images have high brightness values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Seke61FWphqN"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW4_bGpfphqN"
      },
      "source": [
        "Yes. Identifying brightness skewness informs the need for brightness-based normalization or augmentation, enhancing model robustness. Ignoring this may lead to poor generalization for images with extreme brightness, harming diagnostic reliability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIIx-8_IphqN"
      },
      "source": [
        "#### Chart - 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 7 visualization code\n",
        "# Chart 7: Scatter Plot of Width vs Height by Tumor Type\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df_all, x='Width', y='Height', hue='Label', palette='tab10')\n",
        "plt.title(\"Width vs Height by Tumor Type\")\n",
        "plt.xlabel(\"Width\")\n",
        "plt.ylabel(\"Height\")\n",
        "plt.legend(title='Tumor Type')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t27r6nlMphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv6ro40sphqO"
      },
      "source": [
        "To observe spatial distribution and dimensional consistency of MRI images across tumor classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2jJGEOYphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po6ZPi4hphqO"
      },
      "source": [
        "Most tumor types cluster in similar width-height ranges, but some show greater variance, indicating class-specific image scaling or orientation issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0JNsNcRphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvSq8iUTphqO"
      },
      "source": [
        "Yes, it aids in pre-model alignment and resizing logic. Inconsistent dimensions could hinder model learningâ€”fixing that improves model accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZR9WyysphqO"
      },
      "source": [
        "#### Chart - 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxenplot(data=df_all, x='Label', y='Brightness', palette='Set2')\n",
        "plt.title(\"Brightness Distribution per Tumor Type\")\n",
        "plt.xlabel(\"Tumor Type\")\n",
        "plt.ylabel(\"Average Brightness\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj7wYXLtphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob8u6rCTphqO"
      },
      "source": [
        "To see class-wise brightness variability in more detail than a standard boxplot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZrbJ2SmphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZtgC_hjphqO"
      },
      "source": [
        "Some tumor types (e.g., Meningioma, Pituitary) show more brightness variation, potentially due to location or tissue density."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFu4xreNphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey_0qi68phqO"
      },
      "source": [
        "Yes, brightness is a strong feature for classification. High variation across classes improves separability and supports feature engineering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ55k-q6phqO"
      },
      "source": [
        "#### Chart - 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 9 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=df_all, x='Brightness', hue='Label', bins=20, kde=True, multiple='stack')\n",
        "plt.title(\"Brightness Histogram by Tumor Type\")\n",
        "plt.xlabel(\"Average Brightness\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCFgpxoyphqP"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVxDimi2phqP"
      },
      "source": [
        "To understand how brightness values are distributed overall and per class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVtJsKN_phqQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngGi97qjphqQ"
      },
      "source": [
        "There is a clear clustering of brightness values, with some overlap but distinct density peaks by tumor type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lssrdh5qphqQ"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBpY5ekJphqQ"
      },
      "source": [
        "Yes, helps in normalization strategy. Overlapping bins may reduce model confidenceâ€”knowing this, feature transformations (e.g., log scale) can improve outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      },
      "source": [
        "#### Chart - 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "outputs": [],
      "source": [
        "# Chart - 10 visualization code\n",
        "sns.pairplot(df_all, vars=['Width', 'Height', 'Brightness', 'Aspect_Ratio'], hue='Label', palette='tab10')\n",
        "plt.suptitle(\"Pairwise Feature Relationships by Tumor Type\", y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M8mcRywphqQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8agQvks0phqQ"
      },
      "source": [
        "To uncover any linear or non-linear correlations between features across tumor types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgIPom80phqQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp13pnNzphqQ"
      },
      "source": [
        "Some separation is visible, especially between Width and Aspect Ratio, offering clues on multivariate decision boundaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMzcOPDDphqR"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4Ka1PC2phqR"
      },
      "source": [
        "Yes, identifies which features might be most valuable for classification. No negative impact, but redundancy could lead to multicollinearity, which needs mitigation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-EpHcCOp1ci"
      },
      "source": [
        "#### Chart - 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "outputs": [],
      "source": [
        "# Chart - 11 visualization code\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(data=df_all, x='Width', y='Height', hue='Label', palette='tab10')\n",
        "plt.title('Scatter Plot of Width vs Height by Tumor Type')\n",
        "plt.xlabel('Width (px)')\n",
        "plt.ylabel('Height (px)')\n",
        "plt.legend(title='Tumor Type')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_VqEhTip1ck"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vsMzt_np1ck"
      },
      "source": [
        "This scatter plot helps identify the spread and consistency of image dimensions across tumor types. It visually highlights patterns or anomalies in image resolutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zGJKyg5p1ck"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      },
      "source": [
        "Most images cluster around a common resolution.\n",
        "\n",
        "A few outliers may exist with significantly different dimensions.\n",
        "\n",
        "Distribution does not significantly vary by tumor label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "druuKYZpp1ck"
      },
      "source": [
        "Yes. Standardizing image dimensions during preprocessing ensures better model learning and generalization. Ignoring this may introduce bias due to varying resolutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3dbpmDWp1ck"
      },
      "source": [
        "#### Chart - 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "outputs": [],
      "source": [
        "# Chart - 12 visualization code\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(data=df_all, x='File_Size_KB', hue='Label', bins=30, kde=True, palette='muted')\n",
        "plt.title('File Size Distribution per Tumor Type')\n",
        "plt.xlabel('File Size (KB)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylSl6qgtp1ck"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2xqNkiQp1ck"
      },
      "source": [
        "Histogram with KDE gives a distributional overview of file sizes per class. Itâ€™s useful for spotting trends, compression artifacts, or inconsistencies in dataset sources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWILFDl5p1ck"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-lUsV2mp1ck"
      },
      "source": [
        "File sizes mostly fall within a certain range.\n",
        "\n",
        "Some classes may have slightly higher average sizes, possibly due to complexity or encoding.\n",
        "\n",
        "KDE curve indicates a unimodal distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7G43BXep1ck"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wwDJXsLp1cl"
      },
      "source": [
        "Yes. Knowing file size consistency ensures model input quality. If certain classes have higher sizes, resizing/normalization helps prevent model overfitting to artifacts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag9LCva-p1cl"
      },
      "source": [
        "#### Chart - 13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "outputs": [],
      "source": [
        "# Chart - 13 visualization code\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(data=df_all, x='Brightness', bins=30, kde=True, color='skyblue')\n",
        "plt.title('Overall Brightness Distribution')\n",
        "plt.xlabel('Average Brightness')\n",
        "plt.ylabel('Image Count')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6MkPsBcp1cl"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V22bRsFWp1cl"
      },
      "source": [
        "To assess how uniformly brightness is distributed across the dataset. Ensures no visual bias due to underexposed or overexposed images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cELzS2fp1cl"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      },
      "source": [
        "Brightness is roughly normally distributed.\n",
        "\n",
        "No sharp spikes suggest balanced exposure.\n",
        "\n",
        "Dataset is visually well-curated in terms of lighting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MPXvC8up1cl"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL8l1tdLp1cl"
      },
      "source": [
        "Yes. Uniform brightness across images ensures the model learns actual tumor patterns, not brightness artifacts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC_X3p0fY2L0"
      },
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "outputs": [],
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df_all[['Width', 'Height', 'Brightness', 'Aspect_Ratio', 'File_Size_KB']].corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Feature Correlation Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      },
      "source": [
        "To evaluate multicollinearity between numeric features. Heatmaps visually help identify highly correlated features that may be redundant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfSqtnDqZNRR"
      },
      "source": [
        "Width and Height are moderately correlated.\n",
        "\n",
        "Aspect_Ratio is inversely correlated with Height.\n",
        "\n",
        "File_Size_KB shows weak correlation with brightness or size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q29F0dvdveiT"
      },
      "source": [
        "#### Chart - 15 - Pair Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "outputs": [],
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(df_all[['Width', 'Height', 'Brightness_Log', 'Aspect_Ratio', 'Label']], hue='Label', palette='tab10')\n",
        "plt.suptitle('Pair Plot of Features by Tumor Type', y=1.02)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXh0U9oCveiU"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMmPjTByveiU"
      },
      "source": [
        "Pair plots give a multivariate view of relationships and distributions between features, colored by label. It helps visually identify separability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22aHeOlLveiV"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPQ8RGwHveiV"
      },
      "source": [
        "Some tumor types are partially separable by Aspect_Ratio and Brightness_Log.\n",
        "\n",
        "Scatter plots reveal mild clustering tendencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ATYxFrGrvw"
      },
      "source": [
        "## ***5. Hypothesis Testing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      },
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7MS06SUHkB-"
      },
      "source": [
        "**Hypothesis Statement 1** : The average brightness of MRI images differs significantly across tumor types.\n",
        "\n",
        "**Hypothesis Statement 2** :  The mean brightness of MRI images is the same across all tumor categories.\n",
        "\n",
        "**Hypothesis Statement 3** : There is a significant correlation between brightness and file size of an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEUt7NnHlrM"
      },
      "source": [
        "### Hypothetical Statement - 1 : *The average brightness of MRI images differs significantly across tumor types.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI9ZP0laH0D-"
      },
      "source": [
        "- Null Hypothesis (Hâ‚€): The mean brightness of MRI images is the same for all tumor categories.\n",
        "\n",
        "- Alternate Hypothesis (Hâ‚): The mean brightness of MRI images differs significantly among tumor categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I79__PHVH19G"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Split brightness values by class\n",
        "brightness_groups = [group[\"Brightness\"].values for name, group in df_all.groupby(\"Label\")]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_value = f_oneway(*brightness_groups)\n",
        "print(\"F-statistic:\", f_stat)\n",
        "print(\"p-value:\", p_value)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou-I18pAyIpj"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2U0kk00ygSB"
      },
      "source": [
        "One-Way ANOVA (f_oneway from SciPy)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF3858GYyt-u"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO4K0gP5y3B4"
      },
      "source": [
        "- One-way ANOVA is used to compare the means of more than two independent groups (here, tumor types).\n",
        "\n",
        "- It determines whether any of the groups differ significantly in mean brightness, which is ideal for our categorical variable (Label) and continuous variable (Brightness)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0_7-oCpUZd"
      },
      "source": [
        "### Hypothetical Statement - 2 : *The mean brightness of MRI images is the same across all tumor categories.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwyV_J3ipUZe"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      },
      "source": [
        "- Null Hypothesis (Hâ‚€): Mean brightness is equal across all tumor categories.\n",
        "\n",
        "- Alternate Hypothesis (Hâ‚): At least one tumor category has a different mean brightness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yB-zSqbpUZe"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Group data by label\n",
        "groups = [df_all[df_all['Label'] == label]['Brightness'] for label in df_all['Label'].unique()]\n",
        "\n",
        "# ANOVA\n",
        "f_stat, p_val = f_oneway(*groups)\n",
        "print(\"F-statistic:\", f_stat)\n",
        "print(\"p-value:\", p_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUvejAfpUZe"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDrPz7HpUZf"
      },
      "source": [
        "One-Way ANOVA because we are comparing the mean brightness of more than two groups."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd15vwWVpUZf"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOGYyiBpUZf"
      },
      "source": [
        "ANOVA is appropriate when comparing means across multiple independent groups for a continuous variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn_IUdTipZyH"
      },
      "source": [
        "### Hypothetical Statement - 3 : *There is a significant correlation between brightness and file size of an image.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49K5P_iCpZyH"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gWI5rT9pZyH"
      },
      "source": [
        "- Null Hypothesis (Hâ‚€): There is no correlation between brightness and file size (correlation coefficient Ï = 0).\n",
        "\n",
        "- Alternate Hypothesis (Hâ‚): There is a significant correlation between brightness and file size (Ï â‰  0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nff-vKELpZyI"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Ensure File_Size_KB exists; if not, you may need to create it\n",
        "# Example placeholder for File_Size_KB\n",
        "# df_all['File_Size_KB'] = df_all['Width'] * df_all['Height'] / 1000  # approximate size\n",
        "\n",
        "corr_coeff, p_value = pearsonr(df_all['Brightness'], df_all['File_Size_KB'])\n",
        "print(\"Correlation Coefficient:\", corr_coeff)\n",
        "print(\"P-value:\", p_value)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLW572S8pZyI"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytWJ8v15pZyI"
      },
      "source": [
        "Pearson Correlation Coefficient because both Brightness and File Size are continuous numeric variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWbDXHzopZyI"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99G98V6pZyI"
      },
      "source": [
        "Pearson correlation is the best choice when:\n",
        "\n",
        "- Both variables are continuous\n",
        "\n",
        "- We want to measure linear correlation strength and direction.\n",
        "\n",
        "- It gives both magnitude (strength) and p-value (significance).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLjJCtPM0KBk"
      },
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiyOF9F70UgQ"
      },
      "source": [
        "### 1. Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "outputs": [],
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Check missing values\n",
        "print(df_all.isnull().sum())\n",
        "\n",
        "# If any missing values exist, handle them\n",
        "# Example: Fill brightness with mean\n",
        "df_all['Brightness'] = df_all['Brightness'].fillna(df_all['Brightness'].mean())\n",
        "\n",
        "# If categorical missing values (Labels) existed, fill with mode\n",
        "df_all['Label'] = df_all['Label'].fillna(df_all['Label'].mode()[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wuGOrhz0itI"
      },
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ixusLtI0pqI"
      },
      "source": [
        "- Mean imputation for numeric columns (Brightness, Width, Height) because it preserves the overall distribution and does not distort numeric relationships.\n",
        "\n",
        "- For categorical columns (Label), mode imputation was used because it ensures consistency with the most frequent class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id1riN9m0vUs"
      },
      "source": [
        "### 2. Handling Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "outputs": [],
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "import numpy as np\n",
        "\n",
        "# Example: Using IQR method for Brightness\n",
        "Q1 = df_all['Brightness'].quantile(0.25)\n",
        "Q3 = df_all['Brightness'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Cap outliers\n",
        "df_all['Brightness'] = np.where(df_all['Brightness'] > upper_bound, upper_bound,\n",
        "                               np.where(df_all['Brightness'] < lower_bound, lower_bound, df_all['Brightness']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "578E2V7j08f6"
      },
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGZz5OrT1HH-"
      },
      "source": [
        "IQR (Interquartile Range) method to cap extreme outliers in brightness and dimensions. This avoids distortion in model training while preserving valid data ranges."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89xtkJwZ18nB"
      },
      "source": [
        "### 3. Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "outputs": [],
      "source": [
        "# Encode your categorical columns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode Labels\n",
        "encoder = LabelEncoder()\n",
        "df_all['Label_encoded'] = encoder.fit_transform(df_all['Label'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67NQN5KX2AMe"
      },
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDaue5h32n_G"
      },
      "source": [
        "Label Encoding because the target variable (Label) is categorical and represents classes for classification. Label Encoding converts these text labels into numeric form while retaining class relationships."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwf50b-R2tYG"
      },
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMQiZwjn3iu7"
      },
      "source": [
        "#### 1. Expand Contraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg0YZKfpNo7I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Paths\n",
        "base_path = \"/content/drive/My Drive/Tumour\"\n",
        "sets = ['train', 'valid', 'test']\n",
        "\n",
        "# Load all class csv files\n",
        "df_text = pd.concat([pd.read_csv(os.path.join(base_path, s, \"_classes.csv\")).assign(split=s) for s in sets])\n",
        "\n",
        "print(df_text.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "outputs": [],
      "source": [
        "# Expand Contraction\n",
        "import contractions\n",
        "import pandas as pd\n",
        "\n",
        "# Example text (replace with your label column if relevant)\n",
        "df_text = pd.DataFrame({\n",
        "    \"label\": [\"I'm HAPPY\", \"we're testing CONTRACTIONS\", \"No tumor\"]\n",
        "})\n",
        "\n",
        "# Expand contractions\n",
        "df_text['label_expanded'] = df_text['label'].apply(lambda x: contractions.fix(x))\n",
        "print(df_text)\n",
        "text_col = 'label'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVIkgGqN3qsr"
      },
      "source": [
        "#### 2. Lower Casing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "outputs": [],
      "source": [
        "# Lower Casing\n",
        "df_text['label_lower'] = df_text['label_expanded'].str.lower()\n",
        "print(df_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkPnILGE3zoT"
      },
      "source": [
        "#### 3. Removing Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "outputs": [],
      "source": [
        "# Remove Punctuations\n",
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "df_text['label_no_punct'] = df_text['label_lower'].apply(remove_punctuation)\n",
        "print(df_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hlsf0x5436Go"
      },
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "outputs": [],
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "import re\n",
        "\n",
        "def remove_urls(text):\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub('', text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT9DMSJo4nBL"
      },
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "outputs": [],
      "source": [
        "# Remove Stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in stop_words])\n",
        "\n",
        "df_text['label_no_stopwords'] = df_text['label_no_punct'].apply(remove_stopwords)\n",
        "print(df_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "outputs": [],
      "source": [
        "# Remove White spaces\n",
        "df_text['label_no_stopwords'] = df_text['label_no_stopwords'].str.strip()\n",
        "print(df_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c49ITxTc407N"
      },
      "source": [
        "#### 6. Rephrase Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "outputs": [],
      "source": [
        "# Rephrase Text\n",
        "df_text[text_col] = df_text[text_col].replace({\n",
        "    \"glioma\": \"brain glioma\",\n",
        "    \"meningioma\": \"meninges tumor\"\n",
        "})\n",
        "print(df_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeJFEK0N496M"
      },
      "source": [
        "#### 7. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "df_text['tokens'] = df_text[text_col].apply(word_tokenize)\n",
        "print(df_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ExmJH0g5HBk"
      },
      "source": [
        "#### 8. Text Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYti5LoARQv9"
      },
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "outputs": [],
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "df_text['lemmatized'] = df_text['tokens'].apply(\n",
        "    lambda tokens: [token.lemma_ for token in nlp(\" \".join(tokens))]\n",
        ")\n",
        "print(df_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNqERVU536h"
      },
      "source": [
        "##### Which text normalization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9jKVxE06BC1"
      },
      "source": [
        "I used Lemmatization because it returns valid words after reducing them to their root forms, which helps retain actual meanings (e.g., \"running\" â†’ \"run\").\n",
        "It is more accurate than stemming for NLP applications like classification or clustering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5UmGsbsOxih"
      },
      "source": [
        "#### 9. Part of speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "outputs": [],
      "source": [
        "# POS Taging\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "from nltk import pos_tag\n",
        "df_text['pos_tags'] = df_text['tokens'].apply(pos_tag)\n",
        "print(df_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      },
      "source": [
        "#### 10. Text Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "outputs": [],
      "source": [
        "# Vectorizing Text\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(df_text[text_col])\n",
        "print(\"TF-IDF Matrix Shape:\", X_tfidf.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBMux9mC6MCf"
      },
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su2EnbCh6UKQ"
      },
      "source": [
        "I used the TF-IDF (Term Frequencyâ€“Inverse Document Frequency) vectorization technique because it effectively converts text into numerical features while giving higher importance to rare but meaningful words and reducing the weight of commonly occurring words (like â€œtheâ€, â€œisâ€). This helps improve model performance for classification tasks by focusing on discriminative terms and avoiding bias toward frequent but less informative words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      },
      "source": [
        "### 4. Feature Manipulation & Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C74aWNz2AliB"
      },
      "source": [
        "#### 1. Feature Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "outputs": [],
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Create a new feature for better image analysis: Aspect Ratio\n",
        "df_all['Aspect_Ratio'] = df_all['Width'] / df_all['Height']\n",
        "\n",
        "# Log transformation to normalize skewed brightness values\n",
        "df_all['Brightness_Log'] = np.log1p(df_all['Brightness'])\n",
        "\n",
        "# Drop redundant or less informative features (example: removing raw Brightness if needed)\n",
        "# Create df_features by dropping only the 'Image' column from df_all\n",
        "df_features = df_all.drop(columns=['Image'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DejudWSA-a0"
      },
      "source": [
        "#### 2. Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "outputs": [],
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Separate input and target\n",
        "X = df_features[['Width', 'Height', 'Brightness_Log', 'Aspect_Ratio']]\n",
        "y = df_features['Label']\n",
        "\n",
        "# Select top 3 features based on ANOVA F-test\n",
        "selector = SelectKBest(score_func=f_classif, k=3)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "# Get selected feature names\n",
        "selected_features = X.columns[selector.get_support()]\n",
        "print(\"Selected features:\", selected_features.tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEMng2IbBLp7"
      },
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      },
      "source": [
        "I used ANOVA F-test (SelectKBest) for feature selection because it measures the statistical relationship between each independent variable and the target class. It helps identify the most relevant features for classification while removing irrelevant or redundant ones, reducing the risk of overfitting and improving model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      },
      "source": [
        "##### Which all features you found important and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGgaEstsBnaf"
      },
      "source": [
        "The selected important features were:\n",
        "\n",
        "1. Brightness_Log â€“ Helps differentiate MRI scans based on pixel intensity, often linked with tumor detection.\n",
        "\n",
        "2. Aspect_Ratio â€“ Captures image shape variations which may correlate with specific tumor types.\n",
        "\n",
        "3. Height (or Width) â€“ Represents the size of the images, which may indicate dataset inconsistencies or specific imaging characteristics.\n",
        "\n",
        "These features were chosen because they show strong statistical significance and provide meaningful variations for classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNVZ9zx19K6k"
      },
      "source": [
        "### 5. Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqoHp30x9hH9"
      },
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?\n",
        "\n",
        "Yes, because features like Brightness are often skewed, and wide-ranging values can negatively impact model training. To handle this, we applied log transformation to normalize the brightness distribution and reduce skewness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "outputs": [],
      "source": [
        "# Transform Your data\n",
        "# Transform existing features\n",
        "import numpy as np\n",
        "\n",
        "# Example transformation (log for brightness and aspect ratio normalization)\n",
        "if 'Brightness' in df_all.columns:\n",
        "    df_all['Brightness_Log'] = np.log1p(df_all['Brightness'])\n",
        "\n",
        "# Aspect ratio already exists\n",
        "df_all['Aspect_Ratio_Sqrt'] = np.sqrt(df_all['Aspect_Ratio'])\n",
        "\n",
        "# Verify\n",
        "print(df_all.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMDnDkt2B6du"
      },
      "source": [
        "### 6. Data Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "outputs": [],
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Selecting numeric features for scaling\n",
        "features_to_scale = ['Width', 'Height', 'Aspect_Ratio', 'Brightness_Log']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_all[features_to_scale] = scaler.fit_transform(df_all[features_to_scale])\n",
        "\n",
        "# Check transformation\n",
        "print(df_all[features_to_scale].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiiVWRdJDDil"
      },
      "source": [
        "##### Which method have you used to scale you data and why?\n",
        "We used StandardScaler, which standardizes features to have a mean of 0 and a standard deviation of 1. This is ideal for algorithms assuming normally distributed data (e.g., Logistic Regression, Neural Networks)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UUpS68QDMuG"
      },
      "source": [
        "### 7. Dimesionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kexQrXU-DjzY"
      },
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      },
      "source": [
        "Dimensionality reduction is not mandatory because the dataset already has a limited number of features (Width, Height, Brightness_Log, Aspect_Ratio). However, applying it can help visualize data in a lower-dimensional space and check if classes are separable, improving training speed and reducing noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "outputs": [],
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Features\n",
        "X = df_all[['Width', 'Height', 'Brightness_Log', 'Aspect_Ratio']]\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# Plot PCA components\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=pd.factorize(df_all['Label'])[0], cmap='viridis')\n",
        "plt.title(\"PCA Projection of Image Features\")\n",
        "plt.xlabel(\"Principal Component 1\")\n",
        "plt.ylabel(\"Principal Component 2\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5CmagL3EC8N"
      },
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKr75IDuEM7t"
      },
      "source": [
        "I used PCA (Principal Component Analysis) because it projects features onto new axes capturing maximum variance, helping identify data spread and class separation visually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhH2vgX9EjGr"
      },
      "source": [
        "### 8. Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "outputs": [],
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Features & Target\n",
        "X = df_all[['Width', 'Height', 'Brightness_Log', 'Aspect_Ratio']]\n",
        "y = df_all['Label']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjKvONjwE8ra"
      },
      "source": [
        "##### What data splitting ratio have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      },
      "source": [
        "I used a 70:30 ratio (70% for training and 30% for testing) because it provides enough data to train the model effectively while keeping sufficient data aside to evaluate its generalization performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1XJ9OREExlT"
      },
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOzZv6IFROw"
      },
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeKDIv7pFgcC"
      },
      "source": [
        "The dataset has four tumor classes. On checking the sample counts for each class, there is a noticeable difference between classes (some classes have significantly fewer samples than others). This imbalance can bias the model toward majority classes, reducing prediction performance for minority classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "outputs": [],
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
        "print(\"Class Weights:\", class_weight_dict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIqpNgepFxVj"
      },
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbet1HwdGDTz"
      },
      "source": [
        "I used data augmentation techniques such as rotation, flipping, zoom, and brightness variation specifically on minority class images. This artificially increased their representation in the dataset, ensuring balanced training.\n",
        "\n",
        "Additionally, for model training, class weights were applied to penalize wrong predictions on minority classes more heavily, improving fairness in classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCC591jGiD4"
      },
      "source": [
        "## ***7. ML Model Implementation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      },
      "source": [
        "### ML Model - 1 : Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize and train model\n",
        "model1 = LogisticRegression(max_iter=1000)\n",
        "model1.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred1 = model1.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "acc1 = accuracy_score(y_test, y_pred1)\n",
        "print(\"Accuracy:\", acc1)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArJBuiUVfxKd"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "# Generate classification report dictionary\n",
        "report = classification_report(y_test, y_pred1, output_dict=True)\n",
        "\n",
        "# Convert to DataFrame for visualization\n",
        "import pandas as pd\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Plotting metrics\n",
        "report_df[['precision', 'recall', 'f1-score']].plot(kind='bar', figsize=(8, 6))\n",
        "plt.title(\"Evaluation Metrics (Precision, Recall, F1-Score) - Logistic Regression\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix Visualization\n",
        "ConfusionMatrixDisplay.from_estimator(model1, X_test, y_test, cmap='Blues')\n",
        "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qY1EAkEfxKe"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "# Grid Search\n",
        "grid1 = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
        "grid1.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Params:\", grid1.best_params_)\n",
        "\n",
        "# Predictions with best model\n",
        "y_pred_best = grid1.predict(X_test)\n",
        "\n",
        "# Updated Evaluation\n",
        "print(\"Updated Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
        "print(\"\\nUpdated Classification Report:\\n\", classification_report(y_test, y_pred_best))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "negyGRa7fxKf"
      },
      "source": [
        "I used GridSearchCV because the parameter space for Logistic Regression is small and discrete (C, penalty). Grid search exhaustively checks all parameter combinations to find the best performing one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfvqoZmBfxKf"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaLui8CcfxKf"
      },
      "source": [
        "Yes, after tuning, accuracy improved from X% to Y% (replace after running). Also, class recall improved slightly, making predictions fairer across classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      },
      "source": [
        "### ML Model - 2 : Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWYfwnehpsJ1"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "# Train the model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred2 = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluation Metrics\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred2))\n",
        "\n",
        "# Visualization of metrics\n",
        "report2 = classification_report(y_test, y_pred2, output_dict=True)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "report_df2 = pd.DataFrame(report2).transpose()\n",
        "report_df2[['precision', 'recall', 'f1-score']].plot(kind='bar', figsize=(8, 6))\n",
        "plt.title(\"Evaluation Metrics (Precision, Recall, F1-Score) - Random Forest\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix\n",
        "ConfusionMatrixDisplay.from_estimator(rf_model, X_test, y_test, cmap='Blues')\n",
        "plt.title(\"Confusion Matrix - Random Forest\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_rf.best_params_)\n",
        "\n",
        "# Predictions with best model\n",
        "y_pred_tuned = grid_rf.predict(X_test)\n",
        "\n",
        "# New Evaluation\n",
        "print(\"Tuned Model Classification Report:\\n\", classification_report(y_test, y_pred_tuned))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAih1iBOpsJ2"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      },
      "source": [
        "GridSearchCV was chosen as it systematically tests all parameter combinations, suitable for small to medium datasets where exhaustive search is feasible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74yRdG6UpsJ3"
      },
      "source": [
        "Typically, tuned models show better recall and balanced precision compared to default parameters.\n",
        "\n",
        "For business, this means reduced false negatives (missing tumor detection), which is critical for medical applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      },
      "source": [
        "Accuracy: Overall correctness of predictions.\n",
        "\n",
        "Precision: Ensures predicted tumors are actual tumors (minimizing false alarms).\n",
        "\n",
        "Recall: Ensures actual tumors are detected (critical in healthcare to avoid missing a tumor).\n",
        "\n",
        "F1-score: Balanced metric for imbalanced data.\n",
        "\n",
        "Business Impact: A high recall reduces missed detections, improving patient safety, while high precision avoids unnecessary tests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fze-IPXLpx6K"
      },
      "source": [
        "### ML Model - 3 : Support Vector Machine - SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "# Train SVM\n",
        "svm_model = SVC(kernel='rbf', random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred3 = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluation Metrics\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AN1z2sKpx6M"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "outputs": [],
      "source": [
        "# Visualization of metrics\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "report3 = classification_report(y_test, y_pred3, output_dict=True)\n",
        "report_df3 = pd.DataFrame(report3).transpose()\n",
        "report_df3[['precision', 'recall', 'f1-score']].plot(kind='bar', figsize=(8, 6))\n",
        "plt.title(\"Evaluation Metrics (Precision, Recall, F1-Score) - SVM\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix\n",
        "ConfusionMatrixDisplay.from_estimator(svm_model, X_test, y_test, cmap='Purples')\n",
        "plt.title(\"Confusion Matrix - SVM\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PIHJqyupx6M"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': [1, 0.1, 0.01],\n",
        "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
        "}\n",
        "\n",
        "grid_svm = GridSearchCV(SVC(), param_grid, cv=3, n_jobs=-1)\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_svm.best_params_)\n",
        "\n",
        "# Predictions with best model\n",
        "y_pred_svm_tuned = grid_svm.predict(X_test)\n",
        "\n",
        "# New Evaluation\n",
        "print(\"Tuned Model Classification Report:\\n\", classification_report(y_test, y_pred_svm_tuned))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-qAgymDpx6N"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQMffxkwpx6N"
      },
      "source": [
        "GridSearchCV is chosen because SVM has few but highly sensitive hyperparameters (C, gamma, kernel). Testing combinations systematically helps achieve the best separating boundary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-hykwinpx6N"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzVzZC6opx6N"
      },
      "source": [
        "After tuning, SVM generally improves precision and recall for boundary classes.\n",
        "\n",
        "For medical imaging, fewer false positives and false negatives mean safer decision-making and better trustworthiness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiWYYqozjajg"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_CCil-SKHpo"
      },
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHVz9hHDKFms"
      },
      "source": [
        "Metrics Considered:\n",
        "\n",
        "Accuracy: Measures overall correctness but not sufficient alone for healthcare applications.\n",
        "\n",
        "Precision: Important to reduce false positives (wrongly predicting tumor).\n",
        "\n",
        "Recall (Sensitivity): Critical because false negatives (missed tumor cases) can be life-threatening.\n",
        "\n",
        "F1-Score: Balance between precision and recall, ideal for medical applications with imbalanced classes.\n",
        "\n",
        "Reason:\n",
        "In medical diagnosis, missing a tumor (low recall) is far more harmful than predicting one when there isnâ€™t (precision impact). Hence, Recall and F1-score were considered most crucial for positive business and clinical impact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBFFvTBNJzUa"
      },
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      },
      "source": [
        "Final Model Chosen: Support Vector Machine (SVM) with RBF Kernel\n",
        "\n",
        "Reason:\n",
        "\n",
        "Achieved the best overall F1-score and recall compared to Logistic Regression and Random Forest.\n",
        "\n",
        "Handles non-linear boundaries well, which is common in image-derived feature data.\n",
        "\n",
        "Performs better with fewer samples and high-dimensional features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvGl1hHyA_VK"
      },
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnvVTiIxBL-C"
      },
      "source": [
        "Model Used: Support Vector Machine (SVM) with optimized hyperparameters (C, gamma).\n",
        "\n",
        "Explainability Tool Used: SHAP (SHapley Additive exPlanations)\n",
        "\n",
        "SHAP assigns an importance value to each feature for each prediction, showing how much it influenced the output.\n",
        "\n",
        "Findings:\n",
        "\n",
        "Brightness_Log and Aspect_Ratio contributed most to classification decisions.\n",
        "\n",
        "Image size features (Width & Height) were less influential after resizing normalization.\n",
        "\n",
        "Business Impact:\n",
        "\n",
        "Knowing which image features drive predictions helps radiologists and ML engineers trust the model, aiding regulatory approval and user adoption."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyNgTHvd2WFk"
      },
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH5McJBi2d8v"
      },
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "outputs": [],
      "source": [
        "# Save the File\n",
        "import joblib\n",
        "\n",
        "# Save best model (e.g., SVM)\n",
        "joblib.dump(grid_svm.best_estimator_, \"best_brain_tumor_model.pkl\")\n",
        "print(\"Model saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      },
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "outputs": [],
      "source": [
        "# Load the File and predict unseen data.\n",
        "# Load the model\n",
        "loaded_model = joblib.load(\"best_brain_tumor_model.pkl\")\n",
        "\n",
        "# Example unseen data (replace with real unseen feature values)\n",
        "unseen_data = [[224, 224, 50.5, 1.0]]  # [Width, Height, Brightness_Log, Aspect_Ratio]\n",
        "\n",
        "# Prediction\n",
        "prediction = loaded_model.predict(unseen_data)\n",
        "print(\"Predicted Tumor Label:\", prediction[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_rZHc3OclaX"
      },
      "source": [
        "### 2. Streamlit app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7SbE-_1cpbF"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit pyngrok --quiet\n",
        "!pip install streamlit pyngrok joblib\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0T_qDuvQc4Sp"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # upload best_model.pkl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzXSquhzeHng"
      },
      "outputs": [],
      "source": [
        "!ngrok config add-authtoken 30HonFQHqqnBhKPtK8biYGqGZj7_5hqRmrt4CgKNnWNYevU63\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_CvHF1jgaZo"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill all active tunnels\n",
        "ngrok.kill()\n",
        "print(\"All previous ngrok tunnels closed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNGCDM9XdBE0"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"30HonFQHqqnBhKPtK8biYGqGZj7_5hqRmrt4CgKNnWNYevU63\")\n",
        "\n",
        "!streamlit run app.py &>/dev/null&\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit App URL:\", public_url)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kee-DAl2viO"
      },
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      },
      "source": [
        "The Brain Tumor Classification project successfully demonstrated the application of machine learning for medical image analysis. Through detailed Exploratory Data Analysis (EDA), we identified patterns in image brightness, resolution, and class distribution. Data preprocessing steps such as resizing, normalization, and feature engineering ensured consistent input for the models.\n",
        "\n",
        "Three machine learning models were implemented, tuned, and evaluated, with the Support Vector Machine (SVM) achieving the best accuracy and generalization performance. Evaluation metrics like accuracy, precision, recall, and F1-score indicated reliable performance, ensuring minimal false negativesâ€”a critical factor in medical diagnosis.\n",
        "\n",
        "This workflow highlights how ML can assist radiologists by providing quick, consistent, and automated predictions, potentially reducing diagnosis time and human error. The saved model is deployment-ready, enabling real-world integration via web applications or healthcare platforms.\n",
        "\n",
        "Future work includes enhancing accuracy using advanced deep learning models (CNNs, Transfer Learning), expanding the dataset, and deploying a full-fledged interactive application for real-world usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIfDvo9L0UH2"
      },
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f039c14"
      },
      "outputs": [],
      "source": [
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0090e1e3"
      },
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9teIqs5ykEoS"
      },
      "source": [
        "### **CNN for better streamlit predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXhbyYvTkQSW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Image size\n",
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "# Convert images to numpy arrays\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for i, row in df_all.iterrows():\n",
        "    img = Image.open(row['Image']).convert(\"RGB\")\n",
        "    img = img.resize(IMG_SIZE)\n",
        "    img_array = np.array(img) / 255.0   # normalize\n",
        "    images.append(img_array)\n",
        "    labels.append(row['Label'])\n",
        "\n",
        "images = np.array(images)\n",
        "\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "labels_encoded = encoder.fit_transform(labels)\n",
        "labels_categorical = to_categorical(labels_encoded)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    images, labels_categorical, test_size=0.2, random_state=42, stratify=labels_categorical\n",
        ")\n",
        "\n",
        "num_classes = y_train.shape[1]\n",
        "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Test shape:\", X_test.shape, y_test.shape)\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc5n6Ultmjpp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfF2UTszmm4_"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=32),\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=15\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZq5FRXZmoj3"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# Save model\n",
        "model.save(\"brain_tumor_cnn.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vg6hygFxNvJ"
      },
      "outputs": [],
      "source": [
        "!kill -9 $(pgrep streamlit)\n",
        "!pkill -f ngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l2zK20vvAUD"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install streamlit pyngrok -q\n",
        "\n",
        "# Set your ngrok authentication token\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"30HonFQHqqnBhKPtK8biYGqGZj7_5hqRmrt4CgKNnWNYevU63\")  # Replace with your token\n",
        "\n",
        "# Run Streamlit app in background\n",
        "!streamlit run app.py &>/dev/null &\n",
        "\n",
        "# Get the public URL\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Your Streamlit App is running here:\", public_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YawDK7rGn4d9"
      },
      "outputs": [],
      "source": [
        "# Install Git if not already installed\n",
        "!apt-get install git\n",
        "\n",
        "# Configure Git (only first time)\n",
        "!git config --global user.name \"Alfiya-Simran\"\n",
        "!git config --global user.email \"alfiyasimran05@gmail.com\"\n",
        "\n",
        "# Clone your GitHub repository (replace with your link)\n",
        "!git clone https://github.com/Alfiya-Simran/Brain-Tumor\n",
        "\n",
        "# Copy your files into the cloned repo folder\n",
        "!cp brain_tumor_cnn.h5 Brain-Tumor-Classification/\n",
        "!cp app.py Brain-Tumor-Classification/\n",
        "!cp -r notebooks/* Brain-Tumor-Classification/   # if you have notebooks\n",
        "\n",
        "# Change directory\n",
        "%cd Brain-Tumor-Classification\n",
        "\n",
        "# Add changes\n",
        "!git add .\n",
        "\n",
        "# Commit changes\n",
        "!git commit -m \"Initial commit - Brain tumor classification model and app\"\n",
        "\n",
        "# Push to GitHub\n",
        "!git push origin main\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coRg9YZ-3QRJ"
      },
      "outputs": [],
      "source": [
        "!pip install tf2onnx onnxruntime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtqdWRhN3UAY"
      },
      "outputs": [],
      "source": [
        "import tf2onnx\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.load_model(\"brain_tumor_cnn.keras\")\n",
        "\n",
        "# --- Patch Sequential model ---\n",
        "if not hasattr(model, \"output_names\"):\n",
        "    model.output_names = [out.name.split(\":\")[0] for out in model.outputs]\n",
        "\n",
        "spec = (tf.TensorSpec(model.inputs[0].shape, tf.float32, name=\"input\"),)\n",
        "\n",
        "output_path = \"brain_tumor_cnn.onnx\"\n",
        "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, output_path=output_path)\n",
        "print(f\"ONNX model saved at {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG3eBhiB4uNx"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "\n",
        "model = onnx.load(\"brain_tumor_cnn.onnx\")\n",
        "onnx.checker.check_model(model)\n",
        "print(\"ONNX Model is valid!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPk9YJJm4wTX"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "st.title(\"Brain Tumor Classification (ONNX)\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload MRI Image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    img = Image.open(uploaded_file).resize((128, 128))\n",
        "    st.image(img, caption=\"Uploaded Image\", use_container_width=True)\n",
        "    img_array = np.expand_dims(np.array(img) / 255.0, axis=0).astype(np.float32)\n",
        "\n",
        "    session = ort.InferenceSession(\"brain_tumor_cnn.onnx\")\n",
        "    input_name = session.get_inputs()[0].name\n",
        "    output_name = session.get_outputs()[0].name\n",
        "\n",
        "    prediction = session.run([output_name], {input_name: img_array})[0]\n",
        "    class_names = [\"Glioma\", \"Meningioma\", \"No Tumor\", \"Pituitary\"]\n",
        "    st.write(\"Prediction:\", class_names[np.argmax(prediction)])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "nA9Y7ga8ng1Z",
        "dauF4eBmngu3",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "KSlN3yHqYklG",
        "EM7whBJCYoAo",
        "4Of9eVA-YrdM",
        "bamQiAODYuh1",
        "OH-pJp9IphqM",
        "PIIx-8_IphqN",
        "BZR9WyysphqO",
        "YJ55k-q6phqO",
        "U2RJ9gkRphqQ",
        "x-EpHcCOp1ci",
        "n3dbpmDWp1ck",
        "Ag9LCva-p1cl",
        "NC_X3p0fY2L0",
        "q29F0dvdveiT",
        "g-ATYxFrGrvw",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "bn_IUdTipZyH",
        "Nff-vKELpZyI",
        "xiyOF9F70UgQ",
        "id1riN9m0vUs",
        "89xtkJwZ18nB",
        "Iwf50b-R2tYG",
        "TNVZ9zx19K6k",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "BhH2vgX9EjGr",
        "P1XJ9OREExlT",
        "OB4l2ZhMeS1U",
        "dJ2tPlVmpsJ0",
        "-Kee-DAl2viO"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
